{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeSoup(url):\n",
    "    response=requests.get(url)\n",
    "    soup=BeautifulSoup(response.content,\"lxml\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is a way to try and find the special characteristics of the episode. Check back later on how this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def findBetween( s, first, last ):\n",
    "    try:\n",
    "        start = s.index( first ) + len( first )\n",
    "        end = s.index( last, start )\n",
    "        return s[start:end]\n",
    "    except ValueError:\n",
    "        return \"\"\n",
    "\n",
    "def findBetweenR( s, first, last ):\n",
    "    try:\n",
    "        start = s.rindex( first ) + len( first )\n",
    "        end = s.rindex( last, start )\n",
    "        return s[start:end]\n",
    "    except ValueError:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def removePrefix(text, prefix):\n",
    "    return text[len(prefix):] if text.startswith(prefix) else text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = makeSoup('https://en.wikipedia.org/wiki/The_Bachelorette_(season_4)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def soupCleanser(soup):\n",
    "    import re\n",
    "    import numpy as np\n",
    "    # make the soup\n",
    "    \n",
    "    # find the right table\n",
    "    tables = soup.findChildren('table')\n",
    "    table = tables[2]\n",
    "    \n",
    "    # find the descriptive colors in hex format\n",
    "    descript_colors_cols = soup.findChildren('dd')\n",
    "    styles = [color.span['style'] for color in descript_colors_cols]\n",
    "    colors = [findBetween(color,\"background-color:\",\";\") for color in styles]\n",
    "    \n",
    "    \n",
    "    messy_color_codes = [dd.text for dd in descript_colors_cols]\n",
    "    color_codes = [removePrefix(code,\"\\xa0\\xa0\\xa0\\xa0 \") for code in messy_color_codes]\n",
    "    \n",
    "    color_dict = dict(zip(colors, color_codes))\n",
    "\n",
    "    # turn the data into a workable format\n",
    "    data   = [[td.text for td in row.select('td')]\n",
    "             for row in table.findAll('tr')]\n",
    "    \n",
    "    body = data[1:][1:]\n",
    "    cols   =  zip(*body)\n",
    "    \n",
    "    b = [[re.sub(r'\\[\\w+\\]', '', i) for i in row]\n",
    "        for row in body]\n",
    "    \n",
    "    for i in body:\n",
    "        if len(i) == len(body[0]):\n",
    "            pass\n",
    "        else:\n",
    "            a = [\" \"]\n",
    "            a.extend(\" \" * (len(body[0])))\n",
    "            diff = len(a) - len(i) \n",
    "            n = i.extend( a[0:diff])\n",
    "                \n",
    "    contestants = [row[0] for row in body]\n",
    "    \n",
    "    # create lists of call out\n",
    "    call_out_order_list = []\n",
    "    for i in list(np.arange(0,(len(body[0])-1))):\n",
    "        c = [row[i] for row in body] # column\n",
    "        ci = list(np.arange(1,len(c) + 1)) # column index/counter\n",
    "        cdict = dict(zip(c, ci)) # creaet dictionary\n",
    "        col_out_col = [cdict.get(k, 'eliminated') for k in contestants] # call out order\n",
    "        call_out_order_list.append(col_out_col)\n",
    "    \n",
    "    call_out_order_list[0] = contestants # replace first row with contestant names\n",
    "    \n",
    "    # find headers for data frame creation\n",
    "    d = [[td.text for td in row.select('th')]\n",
    "        for row in table.findAll('tr')]\n",
    "    \n",
    "    season_headers = d[1]\n",
    "    header = [\"contestants\"] + season_headers  \n",
    "    \n",
    "    vov = dict(zip(header, call_out_order_list))\n",
    "    \n",
    "    return vov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': [15,\n",
       "  11,\n",
       "  5,\n",
       "  8,\n",
       "  3,\n",
       "  14,\n",
       "  'eliminated',\n",
       "  2,\n",
       "  'eliminated',\n",
       "  10,\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  9,\n",
       "  13,\n",
       "  4,\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  6,\n",
       "  7,\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  12,\n",
       "  'eliminated',\n",
       "  1],\n",
       " '2': [7,\n",
       "  1,\n",
       "  2,\n",
       "  10,\n",
       "  'eliminated',\n",
       "  8,\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  12,\n",
       "  4,\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  6,\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  9,\n",
       "  'eliminated',\n",
       "  'eliminated'],\n",
       " '3': [7,\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  9,\n",
       "  12,\n",
       "  2,\n",
       "  'eliminated',\n",
       "  5,\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  4,\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  1,\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  3,\n",
       "  'eliminated',\n",
       "  'eliminated'],\n",
       " '4': [7,\n",
       "  'eliminated',\n",
       "  6,\n",
       "  2,\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  1,\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  5,\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  9,\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  8,\n",
       "  'eliminated',\n",
       "  4],\n",
       " '5': ['eliminated',\n",
       "  'eliminated',\n",
       "  3,\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  2,\n",
       "  'eliminated',\n",
       "  4,\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  1],\n",
       " '6': ['eliminated',\n",
       "  'eliminated',\n",
       "  4,\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  3,\n",
       "  'eliminated',\n",
       "  1,\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  2],\n",
       " '7': ['eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  2,\n",
       "  'eliminated',\n",
       "  1,\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  'eliminated',\n",
       "  3],\n",
       " 'contestants': ['Brian - TX',\n",
       "  'Paul',\n",
       "  'Graham',\n",
       "  'Sean',\n",
       "  'Richard',\n",
       "  'Jason',\n",
       "  'Spero',\n",
       "  'Jesse',\n",
       "  'John',\n",
       "  'Chris',\n",
       "  'Brian - IN',\n",
       "  'Jeffrey',\n",
       "  'Donato',\n",
       "  'Ryan',\n",
       "  'Twiley',\n",
       "  'Ronald',\n",
       "  'Patrick C.',\n",
       "  'Luke',\n",
       "  'Eric',\n",
       "  'Robert',\n",
       "  'Chandler',\n",
       "  'Greg',\n",
       "  'Fred',\n",
       "  'Patrick D.',\n",
       "  'Jeremy']}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soupCleanser(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'james'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "#for name in tbl_d['name']:\n",
    "cleaned_name = re.sub(r'\\[\\w+\\]', '', \"james\")\n",
    "#new_names.append(cleaned_name)\n",
    "cleaned_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#def dataCollector(soup):\n",
    "#    import re\n",
    "#    import numpy as np\n",
    "#    # make the soup\n",
    "#    this = makeSoup(soup)\n",
    "#    \n",
    "#    # find the right table\n",
    "#    tables = this.findChildren('table')\n",
    "#    table = tables[2]\n",
    "#    \n",
    "#    \n",
    "#    # find the descriptive colors in hex format\n",
    "#    descript_colors_cols = this.findChildren('dd')\n",
    "#    styles = [color.span['style'] for color in descript_colors_cols]\n",
    "#    colors = [findBetween(color,\"background-color:\",\";\") for color in styles]\n",
    "#    \n",
    "#    \n",
    "#    messy_color_codes = [dd.text for dd in descript_colors_cols]\n",
    "#    color_codes = [removePrefix(code,\"\\xa0\\xa0\\xa0\\xa0 \") for code in messy_color_codes]\n",
    "#    \n",
    "#    color_dict = dict(zip(colors, color_codes))\n",
    "#\n",
    "#    # turn the data into a workable format\n",
    "#    data   = [[td.text for td in row.select('td')]\n",
    "#             for row in table.findAll('tr')]\n",
    "#    \n",
    "#    body = data[1:][1:]\n",
    "#    cols   =  zip(*body)\n",
    "#    \n",
    "#    body_n = []\n",
    "#\n",
    "#    for i in body:\n",
    "#        if len(i) == len(body[0]):\n",
    "#            body_n.append(i)\n",
    "#        else:\n",
    "#            a = [\" \"]\n",
    "#            a.extend(\" \" * (len(body[0])))\n",
    "#            diff = len(a) - len(i) \n",
    "#            n = i.extend( a[0:diff])\n",
    "#            body_n.append(n)\n",
    "#                \n",
    "#    # create a dict with the data\n",
    "#    #tbl_d  = {name:col for name, col in zip(header,cols)}\n",
    "#    contestants = [row[0] for row in body]\n",
    "#    \n",
    "#    #c2 = [row[2] for row in body]\n",
    "#    #ci2 = list(np.arange(1,len(c2) + 1))\n",
    "#    #c2dict = dict(zip(c2, ci2))\n",
    "#    \n",
    "#    #yup = [c2dict[x] for x in contestants]\n",
    "#    #yup = [c2dict.get(k, 'eliminated') for k in contestants] # default to eliminated if name doesn't exist\n",
    "#    \n",
    "#    elimination_list = []\n",
    "#    for i in list(np.arange(0,(len(body[0])-1))):\n",
    "#        c = [row[i] for row in body]\n",
    "#        ci = list(np.arange(1,len(c) + 1))\n",
    "#        cdict = dict(zip(c, ci))\n",
    "#        elim_col = [cdict.get(k, 'eliminated') for k in contestants]\n",
    "#        elimination_list.append(elim_col)\n",
    "#          \n",
    "#    return elimination_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#body = dataCollector('https://en.wikipedia.org/wiki/The_Bachelorette_(season_4)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
